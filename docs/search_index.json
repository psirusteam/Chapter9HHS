[["index.html", "CHAPTER 9: ANALYSIS OF HOUSEHOLD SURVEY DATA Abstract", " CHAPTER 9: ANALYSIS OF HOUSEHOLD SURVEY DATA Andrés Gutiérrez1, Pedro Luis do Nascimento Silva2 2024-09-24 Abstract Analyzing complex household survey data requires knowing and properly applying the foundations of the design-based inference. The researcher will be faced to a small database that contains specific information that will allow her to make conclusions over the whole population. The purpose of any analysis on this kind of datasets is not referred to make conclusions on the sample itself – which in most of the cases is a small subgroup of the population - but to the domains of interest and the whole population. Having that into account, the first step in any analysis plan should be devoted to defining the sampling design based on the selection mechanisms used to draw the final sample and the findings on the field related to nonresponse and lack of coverage. The chapter covers three main topics of analysis: descriptive statistics; comparisons and association; and modeling of survey data. On the one hand, we introduce simple descriptive statistics, such as totals, frequencies, means and proportions, quantiles and some graphics; on the other, we delve deeper on complex relationships between the variables of the survey. All these analyses rely on the representativity principle of the design-based inference. This way, the reader will find a strong focus, not only on point estimates, but also on uncertainty measures. The chapter also presents a short discussion on the different approaches that can be used to estimate variances; the best way to visualize the estimates; and NSO practical experiences. Comisión Económica para América Latina y el Caribe (CEPAL) - andres.gutierrez@cepal.org↩︎ SCIENCE, pedronsilva@gmail.com↩︎ "],["introduction.html", "Introduction", " Introduction A key concern of every agency that produces statistical information is with the correct use of the data that it produces. This is even reflected in the United Nations Fundamental Principles of Official Statistics, namely: Principle 3. To facilitate a correct interpretation of the data, the statistical agencies are to present information according to scientific standards on the sources, methods and procedures of the statistics. Principle 4. The statistical agencies are entitled to comment on erroneous interpretation and misuse of statistics. Here we emphasize a particular aspect, aiming to empower users when analysing household survey data. The computer revolution, with the resulting ease of access computers, created favorable conditions for the increased use of statistical data, including those resulting from household sample surveys. Sometimes this data is used for purely descriptive purposes. Other times, however, its use is made for analytical purposes, involving the testing of hypothesis or the construction of models, when the objective is to draw conclusions that are also applicable to populations other than the one from which the sample was extracted. In such cases, standard statistical software may provide biased or misleading results. This chapter’s purpose is to present the relevant models, methods and software to enable users to account for the complex survey design frequently used to conduct household sample surveys when analysing the resulting data. What makes such data special for those who intend to use them for analytical purposes? The answer is that they are obtained through complex sample surveys of finite populations that often involve: stratification, clustering of units of analysis, unequal probabilities of selection, and weighting adjustments to compensate for non-response and/or improve precision. Standard data analysis methods and software typically ignore these aspects, and may produce biased estimates of both the target parameters and the variances of these estimates. In this chapter we analyze the impact of simplifications made when using standard data analysis methods and software, and present the necessary adjustments to these procedures in order to appropriately incorporate the aspects highlighted here into the analysis. In section 9.1, a short discussion on the fundamental principles of the design-based inference is presented, emphasizing that conclusions taken from probability sample surveys should be based on a pair: the point estimate and it associated margin of error (or any related measure). In section 9.2, we begin the journey with simple descriptive statistics: means, ratios, proportions and other typical descriptive parameters. Section 9.3 is devoted to more complex parameters that allow comparisons of the phenomenon of interest between subgroups for continuous and discrete variables. In this section we present standard tests to compare means and measure the degree of association between variables, and also consider the problem of correlation and association. Section 9.4 focuses on modelling survey outcomes. We first involve the reader in an discussion on the role of weighting when estimating regression coefficients. Then, we introduce some proper approaches to estimate complex parameters in linear and logistic regression models. Finally, section 9.5 presents a summary of ideas and tools for survey data visualization showing the best practices for creating graphics and maps in a context where uncertainty measures of estimates are important. Most of the sections in the chapter present national experiences that will guide the reader on how NSOs are dealing with the different stages of the analysis of household survey data. The purpose of this chapter is defining and explaining basic concepts of the design-based paradigm in household surveys to analyze complex household survey data. In section 9.1, a short discussion on the fundamental principles of the design-based inference is presented, emphasizing that conclusions taken from this kind of surveys should be based on a pair: the point estimate and it associated margin of error (or any related measure). In section 9.2, we begin the journey with simple descriptive statistics: means, ratios, proportions and other parameters are part of this discussion. Section 9.3 is devoted to more complex parameters that allow comparisons of the phenomenon of interest between subgroups for continuous and discrete variables. In this section we present standard tests to compare means and measure the degree of association between variables. This section also deals with the problem of correlation and association. Section 9.4 focuses on modelling survey outcomes. We first involve the reader in an discussion on the role of weighting when estimating regression coefficients. Then, we introduce some proper approaches to estimate complex parameters in linear and logistic regression models. Finally, section 9.5 presents a summary on survey data visualization showing the best practices for creating graphics and maps in a context where uncertainty measures of estimates are important. Most of the sections in the chapter present national experiences that will guide the reader on how currently NSOs are dealing with the different stages of the analysis of household survey data. "],["the-golden-pair-sample-design-and-estimator.html", "1 The golden pair: sample design and estimator", " 1 The golden pair: sample design and estimator Accounting for the sampling design is crucial for analyzing complex survey data. We must ensure that PSU, strata, and weights are available in the survey dataset to enable adequate analysis. Alternatively, when such information is not available, the dataset should at least contain replicate weights, or the analyst should have clear guidance on how to compute both point and variance estimates. A well-described survey design facilitates statistical analysis, supports effective data interpretation, and enables meaningful insights into complex phenomena. Missing or incorrect design information may lead to biased estimates and misleading conclusions. "],["parameters-and-estimators.html", "1.1 Parameters and estimators", " 1.1 Parameters and estimators Under a design-based approach this section presents the basic principles of inductive inference and how, using the sampling weights (from chapter VIII), one can get consistent estimators for population parameters of interest. We adopt the notation introduced in chapter VIII for presenting the expressions required here. The population total \\(Y = \\sum _{U} y_k\\) and mean \\(\\overline Y = \\frac Y N\\) of a survey variable \\(y\\) can be estimated by weighted estimators given by \\(\\widehat Y _{HT} = \\sum _{s} d_k \\ y_k\\) and \\(\\overline y_{H} = \\frac {\\widehat Y_{HT}} {\\widehat N_{HT}} = \\frac {\\sum_{s} d_k \\ y_k} {\\sum_{s} d_k}\\), respectively. When the survey weights are calibrated and/or non-response adjusted, the above expressions may still be used, but with the calibrated or non-response adjusted weights, \\(w_k\\) say, replacing the design weights \\(d_k\\), for all \\(k \\in s\\). Here \\(s = \\left\\{ k_1, \\ldots, k_n \\right\\} \\subset U\\) denotes the set of units in a sample selected from the population \\(U\\) using a probability sampling design \\(p(s)\\), that ensures strictly positive first order inclusion probabilities \\(\\pi_k = Pr(k \\in s), \\, \\forall \\, k \\in U\\). These inclusion probabilities are assumed known \\(\\forall \\, k \\in s\\), at least to the data producers. Under the design-based framework and assuming full response, \\(\\widehat Y _{HT}\\) is unbiased for \\(Y\\) and its sampling variance is given by \\[ V_p \\left( \\widehat{Y}_{HT} \\right) = \\sum_{k \\in U} \\sum_{j \\in U} \\left( \\frac {d_k d_j} {d_{kj}} - 1 \\right) y_k y_j \\] where \\(d_{kj} = 1 / \\pi_{kj}\\) and \\(\\pi_{kj} = Pr(k,j \\in s), \\, \\forall \\, k,j \\in U\\). This result assumes that the sampling design \\(p(s)\\) is such that \\(\\pi_{kj} &gt; 0 \\,\\, \\forall \\, k,j \\in U\\). Under full response, this variance can be estimated unbiasedly by \\[ \\widehat {V_p} \\left( \\widehat{Y}_{HT} \\right) = \\sum_{k \\in s} \\sum_{j \\in s} \\left( d_k d_j - d_{kj} \\right) y_k y_j \\] While the above formula for variance estimation is general and covers the vast majority of sample designs used in the practice of household sample surveys, it is not used in practice because the second order inclusion probabilities \\(\\pi_{kj}\\) (and corresponding pairwise weights \\(d_{kj}\\)) are generally unknown to survey data analysts. In fact, even data producers do not compute such pairwise weights, since there are more efficient methods for variance estimation that do not require having such weights. "],["uncertainty-in-household-surveys.html", "1.2 Uncertainty in household surveys", " 1.2 Uncertainty in household surveys As the sample is typically a small subset of the population, it is important to obtain not only point estimates for the parameters of interest, but also the corresponding uncertainty measures and/or confidence intervals. In this subsection we present some approaches for variance estimation: approximate formulas from Taylor linearization and/or the ultimate cluster approach for variances under multi-stage cluster sampling. We also introduce replication methods and generalized variance functions, which are essential when PSU or strata are missing from the sample dataset. A unifying idea of sampling theory is that of estimating equations - David A. Binder (1983b). Many population parameters can be written/obtained as solutions for population estimating equations. A generic population estimating equation is given by $_{i U} z_i () = 0 $, where \\(z_i(\\bullet)\\) is an estimating function evaluated for unit \\(i\\) and \\(\\theta\\) is a population parameter of interest. For the case of the population total, take \\(z_i(\\theta) = y_i - \\theta / N\\). The corresponding population estimation equation is given by \\(\\sum _{i \\in U} (y_i - \\theta / N) = 0\\), and solving for \\(\\theta\\) gives the population total \\(\\theta_U = \\sum _{i \\in U} y_i \\ = \\ Y\\). Similarly, take \\(z_i(\\theta) = y_i - \\theta\\) for the population mean. As a final example, consider the ratio of population totals. Taking \\(z_i(\\theta) = y_i - \\theta x_i\\), the corresponding population estimation equation is given by \\(\\sum _{i \\in U} (y_i - \\theta x_i) = 0\\). Solving for \\(\\theta\\) gives the population ratio \\(\\theta_U = \\sum _{i \\in U} y_i / \\sum _{i \\in U} x_i \\ = \\ R\\). The idea of defining population parameters as solutions to population estimating equations allows defining a general method for obtaining corresponding sample estimators. It is a matter of using the sample estimating equations \\(\\sum _{k \\in s} d_k \\, z_k (\\theta) = 0\\). Under probability sampling, full response and with \\(d_k = 1 / \\pi_k\\), the sample sum in the left hand side is unbiased towards the population sum in the corresponding population estimating equation. Solving the sample estimating equation yields consistent estimators for the corresponding population parameters. The case of the population mean yields the sample estimating equation \\(\\sum _{k \\in s} d_k (y_k - \\theta) = 0\\), and by solving on \\(\\theta\\), we recover the Hàjek estimator \\(\\widehat \\theta = \\sum _{k \\in s} d_k \\, y_k \\, / \\sum _{k \\in s} d_k = \\overline y_H\\). In the case of the population ratio, solving \\(\\sum _{k \\in s} d_k (y_k - \\theta x_k) = 0\\) on \\(\\theta\\), yields the well-known estimator \\(\\widehat \\theta = \\sum _{k \\in s} d_k \\, y_k \\, / \\sum _{k \\in s} d_k \\, x_k = \\widehat R\\). The variance of estimators obtained as solutions of sample estimating equations can be obtained as: \\[ V_p (\\widehat \\theta) \\doteq \\left[ J (\\theta_U) \\right] ^{-1} V_p \\left[ \\sum _{k \\in s} d_k \\, z_k (\\theta_U) \\right] \\left[ J (\\theta_U) \\right] ^{-1} \\] where \\(J (\\theta_U) = \\sum _{k \\in U} \\left[ \\partial{z_k (\\theta)} / \\partial \\theta \\right]_{\\theta = \\theta_U}\\), and \\(\\theta_U\\) is the solution of the corresponding population estimating equation. A consistent estimator of this variance is given by: \\[ \\widehat V_p (\\widehat \\theta) = \\left[ \\widehat J ( \\widehat \\theta) \\right] ^{-1} \\widehat V_p \\left[ \\sum _{k \\in s} d_k \\, z_k (\\widehat \\theta)\\right] \\left[ \\widehat J ( \\widehat \\theta) \\right] ^{-1} \\] where \\(\\widehat J (\\widehat \\theta) = \\sum _{k \\in s} d_i \\, \\left[ \\partial{z_k ( \\theta)} / \\partial \\theta \\right]_{\\theta = \\widehat \\theta}\\). This approach implies that by one is able to estimate many population parameters and corresponding variances using essentially well known methods for estimating totals. Its simplicity and generality have enabled the development of software such as the R survey package, the Stata svy functions and others. References Binder, David A. 1983b. “On the Variances of Asymptotically Normal Estimators from Complex Surveys.” International Statistical Review 51 (3): 279–92. https://doi.org/10.2307/1402588. "],["ultimate-cluster-method.html", "1.3 Ultimate Cluster Method", " 1.3 Ultimate Cluster Method The central idea of the Ultimate Cluster method for variance estimation for estimators of totals in multi-stage cluster sampling designs, proposed by (Hansen1953?), is to consider only the variation between information available in the level of PSUs, and assume that these would have been selected with replacement from the PSU population. This idea is simple, but quite powerful, because it allows to accommodate a variety of sampling designs, involving stratification and selection with unequal probabilities (with or without replacement) of both PSUs as well as lower level sampling units. The requirements for the application of this method are that one has unbiased estimators of totals for the variable of interest for each sampled PSU, and that data are available for at least two sampled PSUs in each stratum (if the sample is stratified in the first stage). Although the method was originally proposed for estimation of variances of estimated totals, it can also be applied in combination with Taylor linearization to obtain variance estimates for estimators of other population quantities that can be obtained as solutions to sample estimating equations. Consider a multi-stage sampling design, in which \\(n_{h}\\) PSUs are selected in stratum \\(h,\\) \\(h=1,\\ldots ,H\\). Let \\(\\pi_{hi}\\) be the inclusion probability of PSU \\(i\\) stratum \\(h\\), and by \\(\\widehat{Y}_{hi}\\) an unbiased estimator of the total \\(Y_{hi}\\) of the survey variable \\(y\\) for the \\(i\\)-th PSU in stratum \\(h\\), \\(h=1,\\ldots ,H\\). Hence an unbiased estimator of the population total \\(Y = \\sum_{h=1}^{H} \\sum_{i=1}^{N_{h}} Y_{hi}\\) is given by \\(\\widehat{Y}_{UC} = \\sum_{h=1}^{H} \\sum_{i=1}^{n_{h}} d_{hi} \\widehat{Y}_{hi}\\), and the ultimate cluster estimator of the corresponding variance is given by: \\[ \\widehat{V}_{UC} \\left( \\widehat{Y}_{UC}\\right) = \\sum_{h=1}^{H} \\frac{n_{h}} {n_{h}-1} \\sum_{i=1}^{n_{h}} \\left( d_{hi} \\widehat{Y}_{hi} - \\frac{\\widehat{Y}_{h}}{n_{h}} \\right) ^{2} \\] where \\(d_{hi} = 1 / \\pi_{hi}\\), \\(\\widehat{Y}_{h} = \\sum_{i=1}^{n_{h}} d_{hi} \\widehat{Y}_{hi}\\) for \\(h=1,\\ldots ,H\\). (See for example, (Shah1993?), p. 4). Although often the selection of primary units can have Primary Cluster estimator presented here may provide a reasonable approximation of the corresponding variance of randomization. This is because sampling plans without replacement are generally more efficient than plans with replacement of equal size. Such an approximation is widely used by sampling practitioners to estimate variances of usual descriptive quantities such as totals and medium (with due adaptation) due to their simplicity, compared to the much greater complexity involved with the employment of variance estimators that attempt to incorporate all steps of plans sampling in several stages. A discussion about Quality of this approximation and alternatives can be found in (SSW92?), p. 153. In some cases, sample replication methods (bootstrap, jackknife) can also be used to estimate variances, as we will see later. "],["using-software-to-generate-valid-inferences.html", "1.4 Using software to generate valid inferences", " 1.4 Using software to generate valid inferences In this part, we advocate to using specialized statistical software to generate efficient estimation processes. Those packages support complex survey data analysis by specifying the survey design using appropriate commands or functions. "],["descriptive-parameters.html", "2 Descriptive parameters", " 2 Descriptive parameters When analyzing complex survey data, several descriptive parameters are meaningful and important. For example: poverty and unemployment rates are simple parameters that allow decision-making for governments; also, income distribution can be used to monitor inequality along time. "],["frequencies.html", "2.1 Frequencies", " 2.1 Frequencies 2.1.1 Point Estimation The accurate estimation of absolute sizes and proportions in household surveys is essential for obtaining representative data that reflects the demographic and socioeconomic reality of a population. These figures serve as the basis for public policy decision-making, resource allocation, and the design of social programs. The ability to understand the distribution of specific categories, such as poverty status, employment status, education level, among others, provides valuable information to address inequalities and promote equitable development. 2.1.1.1 Size Estimates In this section, the processes for estimating categorical variables will be carried out. First, one of the most important parameters is the size of a population, which represents the cardinality of that set; in other words, the total number of individuals that comprise it. In terms of notation, the population size is estimated as follows: \\[ \\hat{N}_{\\omega} = \\sum_{h=1}^{H}\\sum_{\\alpha=1}^{a_{h}}\\sum_{i=1}^{n_{h\\alpha}}\\omega_{h\\alpha i} \\] Similarly, the size estimate in a subpopulation, defined by a dichotomous variable \\(I(y_i = d)\\), which takes the value of one if individual \\(i\\) belongs to category \\(d\\) in the discrete variable, is given by the following expression: \\[ \\hat{N}^d_{\\omega} = \\sum_{h=1}^{H}\\sum_{\\alpha=1}^{a_{h}}\\sum_{i=1}^{n_{h\\alpha}}\\omega_{h\\alpha i}I(y_i = d) \\] "],["means-proportions-and-ratios.html", "2.2 Means, proportions, and ratios", " 2.2 Means, proportions, and ratios After conducting the graphical analysis of trends in the continuous survey variables, it is necessary to obtain point estimates of the measured parameters. These estimates can be obtained either generally for the entire population or disaggregated by domains of interest, depending on the research needs. In the context of household surveys, point estimates refer to the estimation of totals, averages, ratios, means, etc. As mentioned by Heeringa, West, and Berglund (2017), the estimation of totals or averages for a variable of interest in the population, along with the estimation of its variance, has played a crucial role in the development of probability sampling theory. These estimates allow for unbiased and accurate results, providing valuable insights into what is happening in the studied households and enabling informed public policy decision-making. 2.2.1 Total Estimates Once the sampling design is defined, which was done in the previous section, the estimation processes for the parameters of interest are carried out. For the estimation of totals with complex sampling designs that include stratification \\(\\left(h=1,2,...,H\\right)\\) and subsampling in PSUs (assumed to be within stratum \\(h\\)) indexed by \\(\\alpha=1,2,...,a_{h}\\), the estimator for the total can be written as: \\[ \\hat{y}_{\\omega} = \\sum_{h=1}^{H}\\sum_{\\alpha=1}^{a_{h}}\\sum_{i=1}^{n_{h\\alpha}}\\omega_{h\\alpha i}y_{h\\alpha i} \\] Where \\(n_{h\\alpha}\\) is the sample size of households or individuals in PSU \\(\\alpha\\) of stratum \\(h\\); \\(a_{h}\\) is the sample size of PSUs within stratum \\(h\\); \\(H\\) is the total number of strata in the sampling design. Finally, \\(y_{h\\alpha i}\\) and \\(\\omega_{h\\alpha i}\\) correspond respectively to the observation of the variable of interest and the weight (expansion factor) of element \\(i\\) associated with PSU \\(\\alpha\\) within stratum \\(h\\). The unbiased variance estimator for this total estimator \\(\\hat{y}_{\\omega}\\) is: \\[ \\widehat{var}\\left(\\hat{y}_{\\omega}\\right) = \\sum_{h=1}^{H}\\frac{a_{h}}{\\left(a_{h}-1\\right)}\\left[\\sum_{\\alpha=1}^{a_{h}}\\left(\\sum_{i=1}^{n_{h\\alpha}}\\omega_{h\\alpha i}y_{h\\alpha i}\\right)^{2}-\\frac{\\left({ \\sum_{\\alpha=1}^{a_{h}}}\\omega_{h\\alpha i}y_{h\\alpha i}\\right)^{2}}{a_{h}}\\right] \\] As can be seen, calculating the total estimate and its estimated variance is complex. However, these calculations can be performed in R using the svytotal function. The confidence interval is given by the following expression: \\[ \\hat{y}_{\\omega} \\pm 1.96 \\times \\sqrt{\\widehat{var}\\left(\\hat{y}_{\\omega}\\right)} \\] 2.2.2 Estimation of Averages The estimation of the population mean or average is a very important parameter in household surveys. According to Gutiérrez (2016), an estimator of the population mean can be written as a nonlinear ratio of two estimated finite population totals, as follows: \\[ \\hat{\\bar{y}}_{\\omega} = \\frac{\\sum_{h=1}^{H}\\sum_{\\alpha=1}^{a_{h}}\\sum_{i=1}^{n_{h\\alpha}}\\omega_{h\\alpha i}y_{h\\alpha i}}{\\sum_{h=1}^{H}\\sum_{\\alpha=1}^{a_{h}}\\sum_{i=1}^{n_{h\\alpha}}\\omega_{h\\alpha i}} = \\frac{\\hat{y}_{\\omega}}{\\hat{N}_{\\omega}}. \\] It should be noted that if \\(y\\) is a binary variable, the weighted mean estimates the population proportion. On the other hand, since \\(\\hat{\\bar{y}}_{\\omega}\\) is not a linear statistic, there is no closed-form formula for the variance of this estimator. For this reason, resampling methods or Taylor series expansions must be used. In this particular case, using Taylor series, the variance of the estimator is as follows: \\[ var\\left(\\hat{\\bar{y}}_{\\omega}\\right) \\dot{=} \\frac{var\\left(\\hat{y}_{\\omega}\\right)+\\hat{\\bar{y}}_{\\omega}^{2}\\times var\\left(\\hat{N}_{\\omega}\\right)-2\\times\\hat{\\bar{y}}_{\\omega}\\times cov\\left(\\hat{y}_{\\omega},\\hat{N}_{\\omega}\\right)}{\\hat{N}_{\\omega}^{2}}. \\] As can be observed, calculating the variance estimation involves complex components to compute analytically, such as the covariance between the estimated total and the estimated population size. 2.2.3 Proportion Estimation The estimation of a proportion for a binary response variable requires a direct extension of the ratio estimator shown in the previous chapter. As mentioned by Heeringa, West, and Berglund (2017), by recoding the original response categories into a single indicator variable \\(y_{i}\\) with possible values of 1 and 0 (e.g., yes = 1, no = 0), the estimator for a proportion is defined as follows: \\[ \\hat{p}_{\\omega}^d = \\frac{\\hat{N}^d_{\\omega}}{\\hat{N}_{\\omega}} = \\frac{\\sum_{h=1}^{H}\\sum_{\\alpha=1}^{a_{h}}\\sum_{i=1}^{n_{h\\alpha}}\\omega_{h\\alpha i}\\ I(y_i = d)}{\\sum_{h=1}^{H}\\sum_{\\alpha=1}^{a_{h}}\\sum_{i=1}^{n_{h\\alpha}}\\omega_{h\\alpha i}} \\] By applying Taylor linearization to the above estimator, its variance is given by the following expression: \\[ var\\left(\\hat{p}_{\\omega}^d\\right) \\dot{=} \\frac{var\\left(\\hat{N}^{d}_{\\omega}\\right)+(\\hat{p}_{\\omega}^d)^{2}var\\left(\\hat{N}_{\\omega}\\right)-2\\,\\hat{p}_{\\omega}^d\\,cov\\left(\\hat{N}^{d}_{\\omega},\\hat{N}_{\\omega}\\right)}{(\\hat{N}_{\\omega})^{2}} \\] It is common to observe that many statistical packages opt to generate proportion estimates and standard errors on a percentage scale. As is well known in the specialized literature, when the estimated proportion of interest is close to zero or one, the limits of the traditional confidence interval, based on the sampling design, may fall outside the permissible range for proportions. This would have no interpretation due to the nature of the parameter. For this reason, to address this issue, alternative confidence interval estimates based on the sampling design can be used, as proposed by Rust, Hsu, and Westat (2007) and Dean and Pagano (2015). Thus, the confidence interval using the \\(Logit\\left(p\\right)\\) transformation is given by: \\[ IC\\left[logit\\left(p^d\\right)\\right] = \\left\\{ ln\\left(\\frac{\\hat{p}_{\\omega}^d}{1-\\hat{p}_{\\omega}^d}\\right)\\pm\\frac{t_{1-\\alpha/2,\\,gl} \\times se\\left(\\hat{p}_{\\omega}^d\\right)}{\\hat{p}_{\\omega}^d\\left(1-\\hat{p}_{\\omega}^d\\right)}\\right\\} \\] Therefore, the confidence interval for \\(p^d\\) would be: \\[ IC\\left(p^d\\right) = \\left\\{ \\frac{exp\\left[ln\\left(\\frac{\\hat{p}_{\\omega}^d}{1-\\hat{p}_{\\omega}^d}\\right)\\pm\\frac{t_{1-\\alpha/2,\\,gl}\\times se\\left(\\hat{p}_{\\omega}^d\\right)}{\\hat{p}_{\\omega}^d\\left(1-\\hat{p}_{\\omega}^d\\right)}\\right]}{1+exp\\left[ln\\left(\\frac{\\hat{p}_{\\omega}^d}{1-\\hat{p}_{\\omega}^d}\\right)\\pm\\frac{t_{1-\\alpha/2,\\,gl}\\times se\\left(\\hat{p}_{\\omega}^d\\right)}{\\hat{p}_{\\omega}^d\\left(1-\\hat{p}_{\\omega}^d\\right)}\\right]}\\right\\} \\] 2.2.4 Relationship Between Variables In many household survey analyses, it is not sufficient to examine individual variables in isolation. For instance, analyzing the average income of men and women in a country is informative, but comparing the income difference between men and women is crucial for addressing the gender pay gap. This section provides computational tools for estimating ratios and explores hypothesis testing for differences in means, including more complex contrasts. 2.2.4.1 Estimation of Ratios A particular case of a non-linear function of totals is the population ratio. This is defined as the quotient of two population totals for continuous characteristics of interest. In household surveys, there are times when estimating such a parameter is necessary. For example, estimating the ratio of expenditures to income, the number of men per woman, or the number of pets per household in a specific country. Since the ratio is the quotient of two totals, both the numerator and the denominator are unknown quantities and thus need to be estimated. The point estimator for a ratio in complex surveys is the quotient of the estimators for the totals, as defined by: \\[ \\hat{R}_{\\omega} = \\frac{\\hat{y}_{\\omega}}{\\hat{x}_{\\omega}} = \\frac{\\sum_{h=1}^{H}\\sum_{\\alpha=1}^{a_{h}}\\sum_{i=1}^{n_{h\\alpha}}\\omega_{h\\alpha i}y_{h\\alpha i}}{\\sum_{h=1}^{H}\\sum_{\\alpha=1}^{a_{h}}\\sum_{i=1}^{n_{h\\alpha}}\\omega_{h\\alpha i}x_{h\\alpha i}} \\] However, because the ratio estimator is a quotient of two estimators (i.e., a quotient of two random variables), calculating the variance of this estimator is not straightforward. To address this, Taylor linearization methods are applied as demonstrated by Gutiérrez (2016). References Dean, Natalie, and Marcello Pagano. 2015. “Evaluating Confidence Interval Methods for Binomial Proportions in Clustered Surveys.” Journal of Survey Statistics and Methodology 3 (4): 484–503. https://doi.org/10.1093/jssam/smv024. Gutiérrez, H. A. 2016. Estrategias de Muestreo: Diseño de Encuestas y Estimación de Parámetros. Segunda edición. Ediciones de la U. Heeringa, Steven G., Brady T. West, and Patricia A. Berglund. 2017. Applied Survey Data Analysis. Chapman and Hall CRC Statistics in the Social and Behavioral Sciences Series. CRC Press. Rust, Keith F., Valerie Hsu, and Westat. 2007. “Confidence Intervals for Statistics for Categorical Variables from Complex Samples.” In. https://api.semanticscholar.org/CorpusID:195852485. "],["percentiles-and-inequality-measures.html", "2.3 Percentiles and inequality measures", " 2.3 Percentiles and inequality measures In household surveys, it is always necessary to estimate dispersion measures of the studied variables. For example, to understand how disparate incomes are in a given country, which helps inform public policy decisions. Therefore, studying these parameters is crucial. Below is the estimator for the standard deviation: \\[ s_{\\omega}(y) = \\frac{\\sum_{h=1}^{H}\\sum_{\\alpha=1}^{a_{h}}\\sum_{i=1}^{n_{h\\alpha}}\\omega_{h\\alpha i}(y_{h\\alpha i}-\\hat{\\bar{y}}_{\\omega})^{2}}{\\sum_{h=1}^{H}\\sum_{\\alpha=1}^{a_{h}}\\sum_{i=1}^{n_{h\\alpha}}\\omega_{h\\alpha i}-1} \\] Non-central location measures (percentiles) are calculated to determine characteristic points of the data distribution beyond central values. Key non-central location measures include the median, quartiles, and percentiles. In most household surveys, not only are totals, means, and proportions estimated; for some indicators, it is necessary to estimate other parameters, such as medians and percentiles. The median is a measure of central tendency that, unlike the mean, is not easily influenced by outliers, and is thus considered a robust measure. The median is the value that divides the population into two equal parts, implying that half of the population’s observations fall above the median and the other half fall below. On the other hand, the estimation of income percentiles in a given country can define the onset of public policy. For example, a tax could be imposed on individuals in the top 10% of the income distribution, or transport subsidies could be provided to those in the bottom 15% of the income distribution. Quantile estimation is based on results related to weighted total estimators, using an estimation of the cumulative distribution function (CDF) of the population. Specifically, the CDF for a variable \\(y\\) in a finite population of size \\(N\\) is defined as follows: \\[ F(x) = \\frac{\\sum{i=1}^{N}I(y_i \\leq x) }{N} \\] Where \\(I(y_i \\leq x)\\) is an indicator variable that takes the value 1 if \\(y_i\\) is less than or equal to a specific value \\(x\\), and 0 otherwise. An estimator of the CDF in a complex sampling design is given by: \\[ \\hat{F}_{\\omega}(x) = \\frac{\\sum_{h=1}^{H}\\sum_{\\alpha=1}^{a_{h}}\\sum_{i=1}^{n_{h\\alpha}}\\omega_{h\\alpha i}I(y_{i}\\leq x)}{\\sum_{h=1}^{H}\\sum_{\\alpha=1}^{a_{h}}\\sum_{i=1}^{n_{h\\alpha}}\\omega_{h\\alpha i}} \\] Once the CDF is estimated using the survey design weights, the \\(q\\)-th quantile of a variable \\(y\\) is the smallest value of \\(y\\) such that the CDF is greater than or equal to \\(q\\). As is well known, the median is the value where the CDF is greater than or equal to 0.5. Thus, the estimated median is the value where the estimated CDF is greater than or equal to 0.5. Following the recommendations of Heeringa, West, and Berglund (2017), to estimate quantiles, one first considers the order statistics denoted as \\(y_{(1)},\\ldots,y_{(n)}\\) and finds the value of \\(j\\) \\((j=1,\\ldots,n)\\) such that: \\[ \\hat{F}_{\\omega}(y_{j})\\leq q\\leq\\hat{F}_{\\omega}(y_{j+1}) \\] Thus, the estimation of the \\(q\\)-th quantile \\(y_{(q)}\\) in a complex sampling design is given by: \\[ \\hat{y}_{(q)} = y_{j}+\\frac{q-\\hat{F}_{\\omega}(y_{j})}{\\hat{F}_{\\omega}(y_{j+1})-\\hat{F}_{\\omega}(y_{j})}(y_{j+1}-y_{j}) \\] For the variance estimation and confidence intervals of quantiles, Kovar, Rao, and Wu (1988) present results from a simulation study where they recommend using the Balanced Repeated Replication (BRR) technique. 2.3.1 Estimation of the Gini Coefficient Economic inequality is a common issue worldwide, with particular focus from international institutions. Measuring economic inequality among households is of great interest, and the Gini coefficient (\\(G\\)) is the most commonly used indicator for this purpose. The Gini coefficient ranges from 0 to 1, where \\(G = 0\\) indicates perfect equality in wealth distribution, and higher values reflect increasing inequality. Following the estimation equation proposed by David A. Binder and Kovacevic (1995), the estimator for the Gini coefficient is given by: \\[ \\widehat{G}_{\\omega}\\left(y\\right) = \\frac{2 \\times \\sum_{h=1}^{H}\\sum_{\\alpha=1}^{a_{h}}\\sum_{i=1}^{n_{h\\alpha}}\\omega_{h\\alpha i}^{*}\\hat{F}_{\\omega}^{h\\alpha i}y^{h\\alpha i}-1}{\\hat{\\bar{y}}_{\\omega}} \\] where \\(\\omega_{h\\alpha i}^{*}\\) is a normalized weight, defined as: \\[ \\omega_{h\\alpha i}^{*} = \\frac{\\omega_{h\\alpha i}}{\\sum_{h=1}^{H}\\sum_{\\alpha=1}^{a_{h}}\\sum_{i=1}^{n_{h\\alpha}}\\omega_{h\\alpha i}} \\] In this formula, \\(\\hat{F}_{h\\alpha i}{}_{\\omega}\\) represents the estimated cumulative distribution function (CDF) for individual \\(i\\) in cluster \\(\\alpha\\) of stratum \\(h\\), and \\(\\hat{\\bar{y}}_{\\omega}\\) is the estimated mean. Osier (2009) and Langel and Tillé (2013) provide important computational details for estimating the variance of this complex estimator. References Binder, David A., and Milojica S. Kovacevic. 1995. “Estimating Some Measures of Income Inequality from Survey Data: An Application of the Estimating Equations Approach.” Survey Methodology 21 (2): 137–45. Heeringa, Steven G., Brady T. West, and Patricia A. Berglund. 2017. Applied Survey Data Analysis. Chapman and Hall CRC Statistics in the Social and Behavioral Sciences Series. CRC Press. Kovar, J. G., J. N. K. Rao, and C. F. J. Wu. 1988. “Bootstrap and Other Methods to Measure Errors in Survey Estimates.” Canadian Journal of Statistics 16 (Suppl.): 25–45. Langel, Matti, and Yves Tillé. 2013. “Variance Estimation of the Gini Index: Revisiting a Result Several Times Published: Variance Estimation of the Gini Index.” Journal of the Royal Statistical Society: Series A (Statistics in Society) 176 (2): 521–40. https://doi.org/10.1111/j.1467-985X.2012.01048.x. Osier, Guillaume. 2009. “Variance Estimation for Complex Indicators of Poverty and Inequality.” Journal of the European Survey Research Association 3 (3): 167–95. http://ojs.ub.uni-konstanz.de/srm/article/view/369. "],["nso-practical-example.html", "2.4 NSO – Practical example", " 2.4 NSO – Practical example In this subsection a NSO will share how they do disseminate its results on basic descriptive statistics, how they publish the resulting tables and how do they deal with the suppression of estimates that do not reach expected quality. "],["comparisons-and-association.html", "3 Comparisons and association", " 3 Comparisons and association Elaborate analyses of household survey data must be adjusted for the complex survey design to account for clustering, stratification, and weighting. This section will introduce the reader on the main methods currently used to compare subgroups and make conclusions based on a valid inferential context. "],["cross-tabulations.html", "3.1 Cross-tabulations", " 3.1 Cross-tabulations Contingency tables and tests of independence are essential tools in household survey analysis, as they help explore relationships between categorical variables. These tables organize population estimates based on two or more characteristics, revealing patterns and associations. Independence tests evaluate whether the variables are related or independent. This analysis is crucial in research and decision-making, as it provides insights into the dependence between factors, influencing strategies based on accurate estimates. 3.1.1 Contingency Tables In specialized literature, contingency tables are also referred to as cross-tabulations. Generally, a table is assumed to be a two-dimensional array with \\(r=1,\\ldots,R\\) rows and \\(c=1,\\ldots,C\\) columns. These tables are widely used in household survey analysis as they summarize the relationship between categorical variables in terms of frequency counts. A contingency table aims to succinctly represent the association between different categorical variables. For an unexpanded sample, these tables are defined using unweighted frequencies as shown below: Variable 2 Variable 1 0 1 Row Marginal 0 \\(n^{00}\\) \\(n^{01}\\) \\(n^{0+}\\) 1 \\(n^{10}\\) \\(n^{11}\\) \\(n^{1+}\\) Column Marginal \\(n^{+0}\\) \\(n^{+1}\\) \\(n^{++}\\) For weighted analyses based on an expanded sample, the two-way table presents the population estimate of the frequencies as follows: Variable 2 Variable 1 0 1 Row Marginal 0 \\(\\hat{N}^{00}_{\\omega}\\) \\(\\hat{N}^{01}_{\\omega}\\) \\(\\hat{N}^{0+}_{\\omega}\\) 1 \\(\\hat{N}^{10}_{\\omega}\\) \\(\\hat{N}^{11}_{\\omega}\\) \\(\\hat{N}^{1+}_{\\omega}\\) Column Marginal \\(\\hat{N}^{+0}_{\\omega}\\) \\(\\hat{N}^{+1}_{\\omega}\\) \\(\\hat{N}_{\\omega}\\) Thus, considering the subscript \\(i\\in\\left(r,c\\right)\\) represents the individuals classified in cell (\\(r, c\\)), the estimator for the frequency in this cell is given by the following expression: \\[ \\hat{N}^{rc}_{\\omega} = \\sum_{h=1}^{H}\\sum_{\\alpha=1}^{a_{h}}\\sum_{i\\in\\left(r,c\\right)}^{n_{h\\alpha}}\\omega_{h\\alpha i} \\] The estimators for the other frequencies in the table, including row and column marginals, are defined similarly. The estimated proportions from these weighted sample frequencies are obtained as follows: \\[ \\hat{p}_{\\omega}^{rc} = \\frac{\\hat{N}^{rc}_{\\omega}}{\\hat{N}_{\\omega}} \\] On the other hand, it is also possible to create tables that report estimates of relative frequencies, or percentages, in the population. This analysis is, of course, conducted using weighted data based on the expanded sample. The two-way table with the population estimate of proportions is presented below: Variable 2 Variable 1 0 1 Row Marginal 0 \\(\\hat{p}^{00}_{\\omega}\\) \\(\\hat{p}^{01}_{\\omega}\\) \\(\\hat{p}^{0+}_{\\omega}\\) 1 \\(\\hat{p}^{10}_{\\omega}\\) \\(\\hat{p}^{11}_{\\omega}\\) \\(\\hat{p}^{1+}_{\\omega}\\) Column Marginal \\(\\hat{p}^{+0}_{\\omega}\\) \\(\\hat{p}^{+1}_{\\omega}\\) \\(\\hat{p}_{\\omega}\\) In the same way as for absolute frequencies, considering that the subscript \\(i\\in\\left(r,c\\right)\\) represents the individuals classified in cell (\\(r, c\\)), the estimator for the proportion associated with this cell is given by the following expression: \\[ \\hat{p}^{rc}_{\\omega}=\\frac{\\hat{N}^{rc}_{\\omega}}{\\hat{N}_{\\omega}}= \\frac{\\sum_{h=1}^{H}\\sum_{\\alpha=1}^{a_{h}}\\sum_{i\\in\\left(r,c\\right)}^{n_{h\\alpha}}\\omega_{h\\alpha i}}{\\sum_{h=1}^{H}\\sum_{\\alpha=1}^{a_{h}}\\sum_{i=1}^{n_{h\\alpha}}\\omega_{h\\alpha i}} \\] "],["tests-for-group-comparisons.html", "3.2 Tests for group comparisons", " 3.2 Tests for group comparisons To determine whether the means of two groups are significantly different we will introduce t-test and contrasts adjusted for the sampling design. 3.2.1 Hypothesis Test for the Difference of Means A hypothesis test is a statistical procedure used to evaluate evidence in favor of or against a statement or assumption about a population. In this process, a null hypothesis (\\(H_0\\)) is proposed, representing the initial statement that needs to be tested, and an alternative hypothesis (\\(H_1\\)), which is the statement opposing the null hypothesis. This statement may be based on some belief or past experience and will be tested using the evidence gathered from the sample data. If it is suspected that the parameter \\(\\theta\\) is equal to a particular value \\(\\theta_{0}\\), the possible combinations of hypotheses that can be tested are: \\[\\begin{eqnarray*} \\begin{cases} H_{0}: &amp; \\theta=\\theta_{0}\\\\ H_{1}: &amp; \\theta\\neq\\theta_{0} \\end{cases}\\,\\,\\,\\,\\,\\,\\,\\,\\, \\begin{cases} H_{0}: &amp; \\theta=\\theta_{0}\\\\ H_{1}: &amp; \\theta&gt;\\theta_{0} \\end{cases}\\,\\,\\,\\,\\,\\,\\,\\,\\, \\begin{cases} H_{0}: &amp; \\theta=\\theta_{0}\\\\ H_{1}: &amp; \\theta&lt;\\theta_{0} \\end{cases} \\end{eqnarray*}\\] One of the two hypotheses will be considered true only if the statistical evidence, which is obtained from the sample, supports it. The process of selecting one of the two hypotheses is called a Hypothesis Test. In general, some important parameters can be expressed as a linear combination of measures of interest. The most common cases are differences in means, weighted sums of means used to construct economic indices, etc. Thus, consider a function that is a linear combination of \\(j\\) descriptive statistics, as shown below: \\[\\begin{eqnarray*} f\\left(\\theta_{1},\\theta_{2},...,\\theta_{j}\\right) &amp; = &amp; \\sum_{j=1}^{J}a_{j}\\theta_{j} \\end{eqnarray*}\\] In this case, \\(a_{j}\\) are known constants. An estimator of this function is given by: \\[\\begin{eqnarray} \\hat{f}_{\\omega}\\left(\\hat{\\theta}_{1},\\hat{\\theta}_{2},...,\\hat{\\theta}_{j}\\right) &amp; = &amp; \\sum_{j=1}^{J}a_{j}\\hat{\\theta}_{j} \\end{eqnarray}\\] And its variance is calculated as follows: \\[\\begin{eqnarray} var\\left(\\sum_{j=1}^{J}a_{j}\\hat{\\theta}_{j}\\right) &amp; = &amp; \\sum_{j=1}^{J}a_{j}^{2}var\\left(\\hat{\\theta}_{j}\\right)+2\\times\\sum_{j=1}^{J-1}\\sum_{k&gt;j}^{J}a_{j}a_{k}\\,cov\\left(\\hat{\\theta}_{j},\\hat{\\theta}_{k}\\right) \\end{eqnarray}\\] As seen in the variance equation of the estimator, it incorporates the variances of the individual components’ estimates, as well as the covariances of the estimated pairs. Of particular interest is analyzing the difference in population means, which can be written as follows: \\[ \\bar{y}^{1}-\\bar{y}^{2} \\] Where \\(\\bar{y}_{1}\\) is the mean of the first population, for example, the average household income obtained by fathers, and \\(\\bar{y}_{2}\\) is the mean of the second population, which in this example could be the average income of mothers in a household. This parameter can be unbiasedly estimated by: \\[ \\hat{\\bar{y}}_{\\omega}^{1}-\\hat{\\bar{y}}_{\\omega}^{2} \\] Where \\(\\hat{\\bar{y}}_{\\omega}^{i}\\) is the sample estimator of \\(\\bar{y}^{i}\\) (\\(i = 1, 2\\)). Considering the parameter of interest in this section, the hypotheses to be tested are as follows: \\[\\begin{eqnarray*} \\begin{cases} H_{0}:\\bar{y}_{1}-\\bar{y}_{2}=0\\\\ H_{1}:\\bar{y}_{1}-\\bar{y}_{2}\\neq0 \\end{cases} &amp; \\begin{cases} H_{0}:\\bar{y}_{1}-\\bar{y}_{2}=0\\\\ H_{1}:\\bar{y}_{1}-\\bar{y}_{2}&gt;0 \\end{cases} &amp; \\begin{cases} H_{0}:\\bar{y}_{1}-\\bar{y}_{2}=0\\\\ H_{1}:\\bar{y}_{1}-\\bar{y}_{2}&lt;0 \\end{cases} \\end{eqnarray*}\\] To test these hypotheses, the following test statistic is used, which follows a t-student distribution with \\(df\\) degrees of freedom, calculated as the difference between the number of PSUs (Primary Sampling Units) and the number of strata. \\[ t = \\frac{\\hat{\\bar{y}}_{\\omega}^{1}-\\hat{\\bar{y}}_{\\omega}^{2}}{se\\left(\\bar{y}_{1}-\\bar{y}_{2}\\right)} \\sim t_{df} \\] Where: \\[ \\widehat{se}\\left(\\hat{\\bar{y}}_{\\omega}^{1}-\\hat{\\bar{y}}_{\\omega}^{2}\\right) = \\sqrt{\\widehat{var}\\left(\\hat{\\bar{y}}_{\\omega}^{1}\\right) + \\widehat{var}\\left(\\hat{\\bar{y}}_{\\omega}^{2}\\right) - 2 \\ \\widehat{cov}\\left(\\hat{\\bar{y}}_{\\omega}^{1},\\hat{\\bar{y}}_{\\omega}^{2}\\right)} \\] If a confidence interval for the difference in means is desired, it would be constructed as follows: \\[ \\hat{\\bar{y}}_{\\omega}^{1}-\\hat{\\bar{y}}_{\\omega}^{2} \\pm t_{df}\\ \\widehat{se}\\left(\\hat{\\bar{y}}_{\\omega}^{1}-\\hat{\\bar{y}}_{\\omega}^{2}\\right) \\] 3.2.2 Contrasts In many cases, it is necessary to compare more than two populations at the same time. For example, comparing the average household incomes across three regions to identify which regions experienced a greater impact on households. In such cases, the difference of means we studied in previous chapters is not sufficient, as it only allows for pairwise comparisons of populations. Therefore, using contrasts becomes a good alternative to address these types of problems. Based on the definitions discussed in this chapter, a contrast is a linear combination of parameters in the form: \\[\\begin{eqnarray*} f = A * \\theta = f\\left(\\theta^{1},\\theta^{2},...,\\theta^{j}\\right) &amp; = &amp; \\sum_{j=1}^{J}a_{j}\\theta^{j} \\end{eqnarray*}\\] Where \\(A\\) is a matrix or vector of constants, and \\(\\theta\\) is a matrix or vector of parameters. Next, we will perform the calculation of a hypothesis contrast. Suppose we have the estimates shown in the table, where the goal is to compare the average income by region. As a first example, we will compare two populations: the North and South regions. Specifically, we are interested in the income difference (\\(f = \\bar{y}^{North} - \\bar{y}^{South}\\)). Since the population is divided into five regions and the contrast will only be constructed for two of them (North and South), it is defined as follows: \\[ f = A * \\theta = 1 \\times \\bar{y}^{North} + (-1) \\times \\bar{y}^{South} + 0 \\times \\bar{y}^{Center} + 0 \\times \\bar{y}^{West} + 0 \\times \\bar{y}^{East} \\] As can be observed, in this case, the contrast vector is \\(A = \\left[1, -1, 0, 0, 0\\right]\\). Mathematically, the estimator for this specific contrast is defined as: \\[ \\hat{f}_{\\omega} = A \\times \\hat{\\theta} = \\left[1, -1, 0, 0, 0\\right] \\times \\left[ \\begin{array}{c} \\hat{\\bar{y}}^{North}_{\\omega} \\\\ \\hat{\\bar{y}}^{South}_{\\omega} \\\\ \\hat{\\bar{y}}^{Center}_{\\omega} \\\\ \\hat{\\bar{y}}^{West}_{\\omega} \\\\ \\hat{\\bar{y}}^{East}_{\\omega} \\end{array} \\right] \\] Estimation table for regions. Region Income Standard error (se) Lower bound (ci_l) Upper bound (ci_u) North 552.3637 55.35987 443.8603 660.8670 South 625.7740 62.40574 503.4610 748.0870 Center 650.7820 61.46886 530.3053 771.2588 West 517.0071 46.22077 426.4161 607.5982 East 541.7543 71.66487 401.2938 682.2149 To continue with the example, we take the estimated mean incomes for the North and South regions and calculate the difference: \\[ f = A \\times \\theta = 552.4 - 625.8 = -73.4 \\] The next step is to calculate the variance-covariance matrix and extract the variances for the North and South regions: North South Center West East North 3064.715 0.000 0.000 0.000 0.000 South 0.000 3894.476 0.000 0.000 0.000 Center 0.000 0.000 3778.420 0.000 0.000 West 0.000 0.000 0.000 2136.359 0.000 East 0.000 0.000 0.000 0.000 5135.854 Since the sampling is independent in each region, the covariances in the matrix are zero. To calculate the standard error of the difference (contrast), we will use the properties of variance, as follows: \\[ se(\\hat{f}_{\\omega}) = se\\left(\\hat{\\bar{y}}^{North}_{\\omega} - \\hat{\\bar{y}}^{South}_{\\omega}\\right) = \\sqrt{var\\left(\\hat{\\bar{y}}^{North}_{\\omega}\\right) + var\\left(\\hat{\\bar{y}}^{South}_{\\omega}\\right) - 2 \\, cov\\left(\\hat{\\bar{y}}^{North}_{\\omega}, \\hat{\\bar{y}}^{South}_{\\omega}\\right)} \\] Therefore, the estimated standard error for this contrast is: \\[ se(\\hat{f}_{\\omega}) = \\sqrt{3064.715 + 3894.476 - 2 \\times 0} = \\sqrt{6959.191} \\] "],["tests-of-independence.html", "3.3 Tests of Independence", " 3.3 Tests of Independence Based on the estimated tables, it is possible to perform independence tests to verify whether there is an association between two categorical variables. Two variables are independent if the structural behavior of one variable does not depend on the other, and vice versa. Heeringa, West, and Berglund (2017) state that, under simple random sampling, two categorical variables are independent if the expected proportion in row \\(r\\) and column \\(c\\), denoted as \\(\\pi^{rc}\\), follows the relationship: \\[ \\pi^{rc} = \\frac{n^{r+} \\times n^{+c}}{(n^{++})^2} \\] Thus, one way to verify if there is independence between the variables of interest is to directly compare the estimated proportions \\(\\hat{p}^{rc}_{\\omega}\\) with the expected proportions \\(\\pi^{rc}\\). If there is a large difference between them, then the independence hypothesis would not be supported by the collected data. Therefore, the following Rao-Scott \\(\\chi^{2}_{RS}\\) statistic (Rao and Scott 1984b), which follows a chi-square distribution with \\((R-1) \\times (C-1)\\) degrees of freedom, is defined: \\[\\begin{eqnarray} \\chi^{2}_{RS} = \\frac{\\chi^{2}_{Pearson}}{GDEFF} \\end{eqnarray}\\] Where: \\[ \\chi^{2}_{Pearson} = n^{++} \\left( \\sum_r \\sum_c \\frac{(\\hat{p}^{rc}_{\\omega} - \\pi^{rc})^2}{\\pi^{rc}} \\right) \\] Additionally, \\(GDEFF\\) is an estimate of the generalized design effect by Rao–Scott, defined as: \\[ GDEFF = \\frac{\\sum_{r}\\sum_{c}\\left(1-p_{rc}\\right)d^{2}\\left(p_{rc}\\right)-\\sum_{r}\\left(1-p_{r+}\\right)d^{2}\\left(p_{r+}\\right)-\\sum_{c}\\left(1-p_{+c}\\right)d^{2}\\left(p_{+c}\\right)}{\\left(R-1\\right)\\left(C-1\\right)} \\] As mentioned by Heeringa, West, and Berglund (2017), it was Fay (1979), along with Fellegi (1980), who began proposing corrections to Pearson’s chi-square statistic based on a generalized design effect. Rao and Scott (1984a) later expanded the theory of generalized design effect corrections for these statistical tests, as did Thomas and Rao (1987). The Rao-Scott method requires the calculation of generalized design effects, which are analytically more complex than Fellegi’s approach. Rao-Scott corrections are now the standard for analyzing categorical survey data in software systems such as Stata and SAS. Additionally, Fisher’s F-test for independence allows the analysis of whether two dichotomous variables are associated when the observed sample is too small, and the conditions for applying Pearson’s \\(\\chi^{2}\\) test are not met. To use this technique, consider the expressions for the estimated probability and Pearson’s \\(\\chi^{2}\\) statistic. Based on these, the likelihood ratio statistic is defined as: \\[ G^{2} = 2 \\times n_{++} \\times \\sum_{r} \\sum_{c} p_{rc} \\times \\ln \\left( \\frac{p_{rc}}{\\hat{\\pi}_{rc}} \\right) \\] where \\(r\\) is the number of rows, and \\(c\\) represents the number of columns, and the test has \\((R-1) \\times (C-1)\\) degrees of freedom. Applying a correction for the generalized design effect, the likelihood ratio statistic is calculated as: \\[ G^2_{(R-S)} = \\frac{G^2}{GDEFF} \\] Thus, the F-statistic for independence based on Pearson’s chi-square test is calculated as follows: \\[ F_{R-S,Pearson} = \\frac{\\chi^{2}_{R-S}}{\\left[(R-1)(C-1)\\right]} \\sim F_{\\left(R-1\\right)\\left(C-1\\right),df} \\] And, the F-statistic for independence based on the likelihood ratio is calculated as: \\[ F_{R-S,LRT} = \\frac{G^{2}_{R-S}}{(C-1)} \\sim F_{\\left(C-1\\right),df} \\] where \\(C\\) is the number of columns in the cross-tabulation. References Fay, Robert E. 1979. “On Adjusting the Pearson Chi-Square Statistic for Cluster Sampling.” In Proceedings of the Social Statistics Section, American Statistical Association, 402–5. Washington, DC. Fellegi, Ivan P. 1980. “Approximate Tests of Independence and Goodness of Fit Based on Stratified Multistage Samples.” Journal of the American Statistical Association 75: 261–68. Heeringa, Steven G., Brady T. West, and Patricia A. Berglund. 2017. Applied Survey Data Analysis. Chapman and Hall CRC Statistics in the Social and Behavioral Sciences Series. CRC Press. Rao, J. N. K., and A. J. Scott. 1984a. “On Chi-Squared Test for Multiway Contingency Tables with Cell Proportions Estimated from Survey Data.” The Annals of Statistics 12: 46–60. ———. 1984b. “On Chi-Squared Tests for Multiway Contingency Tables with Cell Proportions Estimated from Survey Data.” The Annals of Statistics 12 (1): 46–60. Thomas, D. R., and J. N. K. Rao. 1987. “Small-Sample Comparisons of Level and Power for Simple Goodness-of-Fit Statistics Under Cluster Sampling.” Journal of the American Statistical Association 82: 630–36. "],["correlation.html", "3.4 Correlation", " 3.4 Correlation To conclude on the degree of association between variables, we show the proper approach to include sampling weights and complex sampling design. "],["nso-practical-example-1.html", "3.5 NSO – Practical example", " 3.5 NSO – Practical example In this part an NSO will share its experiences on dealing with statistical comparisons among groups and how do they present the results in tables. "],["regression-modelling-survey-data.html", "4 Regression: modelling survey data", " 4 Regression: modelling survey data Modelling survey data is a common task among researcher; some of them include the features of the sampling design in computing standard error of the estimated regression parameters. In this section we will deal with the problem of weighting in regression models and present a parsimonious solution. "],["to-weight-or-not-to-weight.html", "4.1 To weight or not to weight?", " 4.1 To weight or not to weight? We present the pros and cons of including the complex design features in the estimation of regression parameters and their associated standard errors. We present some adjustment to the sampling weights to fit these kind of models (senate sampling weights, normalized sampling weights, Pfeffermann model weights). "],["some-inferential-approaches-to-modelling-data.html", "4.2 Some inferential approaches to modelling data", " 4.2 Some inferential approaches to modelling data When modelling survey data, one should deal with two sources of variability: the one devoted to the complex sampling design and the one that comes from the very model. Combining these sources into a valid set up requires of some advanced methods. We will mention some of them: pseudo likelihood, combined inference. "],["linear-models.html", "4.3 Linear models", " 4.3 Linear models 4.3.1 Basic Definitions As noted by Heeringa, West, and Berglund (2017), the first authors to empirically discuss the impact of complex sampling designs on regression model inferences were Kish and Frankel (1974). Later, Fuller (1975) developed a variance estimator for regression model parameters based on Taylor linearization with unequal weighting of observations under stratified and two-stage sampling designs. As is well known, the use of regression model theory requires certain statistical assumptions to be met, which can sometimes be challenging to verify in practice. In this regard, Shah, Holt, and Folsom (1977) discuss some aspects related to the violation of these assumptions and provide appropriate methods for making inferences about the estimated parameters of linear regression models using survey data. Similarly, David A. Binder (1983a) obtained the sampling distributions of estimators for regression parameters in finite populations and related variance estimators in the context of complex samples. Skinner, Holt, and Smith (1989) studied the properties of variance estimators for regression coefficients under complex sample designs. Later, Fuller (2002) provided a summary of estimation methods for regression models containing information related to complex samples. Finally, Pfeffermann (2011) discussed various approaches to fitting linear regression models to complex survey data, presenting empirical support for the use of the “q-weighted” method, which is recommended in this document. A simple linear regression model is defined as \\(y=\\beta_{0}+\\beta_{1}x+\\varepsilon\\), where \\(y\\) represents the dependent variable, \\(x\\) is the independent variable, and \\(\\beta_{0}\\) and \\(\\beta_{1}\\) are the model parameters. The variable \\(\\varepsilon\\) is known as the random error of the model and is defined as \\(\\varepsilon=y-\\hat{y}=y-\\beta_{0}+\\beta_{1}x\\). Generalizing the previous model, multiple linear regression models are defined by allowing the dependent variable to interact with more than two variables, as presented below: \\[ y = \\boldsymbol{x}\\boldsymbol{\\beta}+\\varepsilon = \\sum_{j=0}^{p}\\beta_{j}x_{j}+\\varepsilon = \\beta_{0}+\\beta_{1}x_{1}+\\cdots+\\beta_{p}x_{p}+\\varepsilon \\] Another way to write the multiple regression model is: \\[ y_{i} = x_{i}\\boldsymbol{\\beta}+\\varepsilon_{i} \\] Where, \\(x_{i}=\\left[1\\,x_{1i}\\,\\ldots\\,x_{pi}\\right]\\) and \\(\\boldsymbol{\\beta}^{T}=\\left[\\beta_{0}\\,\\,\\beta_{1}\\,\\,\\ldots\\,\\,\\beta_{p}\\right]\\). The subscript \\(i\\) refers to the sample element or respondent in the dataset. Heeringa, West, and Berglund (2017) present some considerations for regression models, which are described below: \\(E\\left(\\varepsilon_{i}\\mid x_{i}\\right)=0\\), meaning that the expected value of the residuals conditioned on the covariates is zero. \\(Var\\left(\\varepsilon_{i}\\mid x_{i}\\right)=\\sigma_{y,x}^{2}\\) (homogeneity of variance), meaning that the variance of the residuals conditioned on the covariates is constant. \\(\\varepsilon_{i}\\mid x_{i}\\sim N\\left(0,\\,\\sigma_{y,x}^{2}\\right)\\) (normality of errors), meaning that the residuals conditioned on the covariates follow a normal distribution. This property also extends to the response variable \\(y_{i}\\). \\(cov\\left(\\varepsilon_{i},\\,\\varepsilon_{j}\\mid x_{i},x_{j}\\right)\\) (independence of residuals), meaning that the residuals in different observed units are not correlated with the values given by their predictor variables. Once the linear regression model and its assumptions are defined, it can be deduced that the best unbiased linear estimator is defined as the expected value of the dependent variable conditioned on the independent variables \\(x\\), as: \\[ E\\left(y\\mid x\\right)=\\hat{\\beta}_{0}+\\hat{\\beta_{1}}x_{1}+\\hat{\\beta}_{2}x_{2}+\\cdots+\\hat{\\beta}_{p}x_{p} \\] \\[ \\hat{y} = E\\left(y\\mid x\\right) = E\\left(\\boldsymbol{x}\\boldsymbol{\\beta}\\right)+E\\left(\\varepsilon\\right) = \\boldsymbol{x}\\boldsymbol{\\beta}+0 = \\beta_{0}+\\beta_{1}x_{1}+\\cdots+\\beta_{p}x_{p} \\] Additionally, \\[ var\\left(y_{i}\\mid x_{i}\\right) = \\sigma_{y,x}^{2} \\] It is also established that: \\[ cov\\left(y_{i},y_{j}\\mid x_{i},x_{j}\\right) = 0 \\] Thus, the response variable has the following distribution: \\[ y_{i} \\sim N\\left(x_{i}\\boldsymbol{\\beta},\\sigma_{y,x}^{2}\\right) \\] 4.3.2 Estimation of Parameters in a Regression Model with Complex Samples Once the assumptions of the model and the distributional characteristics of the errors are established, the next step is the process of parameter estimation. As an illustrative and introductory example, if instead of observing a sample of size \\(n\\) from the \\(N\\) elements of the population, a complete census had been conducted, the finite population regression parameter \\(\\beta_{1}\\) could be calculated as follows: \\[ \\beta_{1} = \\frac{ \\sum_{i=1}^{N}\\left(X_{i}-\\bar{X}\\right)\\left(Y_{i}-\\bar{Y}\\right)}{\\sum_{i=1}^{N}\\left(X_{i}-\\bar{X}\\right)^{2}} \\] Now, when estimating the parameters of a linear regression model considering that the observed information comes from surveys with complex samples, the standard approach to estimating regression coefficients and their standard errors is altered. The main reason for this change is that data collected through a complex survey generally does not have an identical distribution, and the assumption of independence cannot be maintained since the sample design is constructed with dependencies (as most complex designs include stratification, clustering, unequal selection probabilities, etc.). In this context, when fitting regression models with such datasets, using conventional estimators derived from traditional methods (such as maximum likelihood, for example) will induce bias because these methods assume the data are independently and identically distributed and come from a specific probability distribution (binomial, Poisson, exponential, normal, etc.). Instead, according to Wolter (2007), robust non-parametric methods based on Taylor linearization or variance estimation methods using replication (Jackknife, bootstrapping, etc.) are used to eliminate bias by including the sampling design in the analyses. For illustrative purposes, the estimation of the parameter \\(\\beta_{1}\\) and its variance for a simple linear regression will be shown. The extension to multiple regression parameter estimation is algebraically complex and beyond the scope of this book. Below is the estimation of the slope and its variance in a simple linear regression model: \\[ \\hat{\\beta_{1}} = \\frac{\\sum_{h}^{H}\\sum_{\\alpha}^{a_{h}}\\sum_{i=1}^{n_{h\\alpha}}\\omega_{h\\alpha i}\\left(y_{h\\alpha i}-\\hat{\\bar{y}}_{\\omega}\\right)\\left(x_{h\\alpha i}-\\hat{\\bar{x}}_{\\omega}\\right)}{\\sum_{h}^{H}\\sum_{\\alpha}^{a_{h}}\\sum_{i=1}^{n_{h\\alpha}}\\omega_{h\\alpha i}\\left(x_{h\\alpha i}-\\hat{\\bar{x}}_{\\omega}\\right)^{2}} \\] As can be seen in the above equation, the parameter estimator is a ratio of totals; therefore, its variance is given by: References Binder, David A. 1983a. “On the Variances of Asymptotically Normal Estimators from Complex Surveys.” International Statistical Review 51: 279–92. Fuller, Wayne A. 1975. “Regression Analysis for Sample Survey.” Sankyha, Series C 37: 117–32. ———. 2002. “Regression Estimation for Survey Samples (with Discussion).” Survey Methodology 28 (1): 5–23. Heeringa, Steven G., Brady T. West, and Patricia A. Berglund. 2017. Applied Survey Data Analysis. Chapman and Hall CRC Statistics in the Social and Behavioral Sciences Series. CRC Press. Kish, Leslie, and Martin R Frankel. 1974. “Inference from Complex Samples.” Journal of the Royal Statistical Society, Series B 36: 1–37. Pfeffermann, Danny. 2011. “Modelling of Complex Survey Data: Why Model? Why Is It a Problem? How Can We Approach It?” Survey Methodology 37 (2): 115–36. Shah, B. V., M. M. Holt, and R. F. Folsom. 1977. “Inference about Regression Models from Sample Survey Data.” Bulletin of the International Statistical Institute 41 (3): 43–57. Skinner, Chris J, Daniell Holt, and Tom M F Smith. 1989. Analysis of Complex Surveys. New York: John Wiley &amp; Sons. Wolter, Kirk M. 2007. Introduction to Variance Estimation. 2nd ed. Statistics for Social and Behavioral Sciences. Springer. "],["references.html", "References", " References Binder, David A. 1983a. “On the Variances of Asymptotically Normal Estimators from Complex Surveys.” International Statistical Review 51: 279–92. Binder, David A. 1983b. “On the Variances of Asymptotically Normal Estimators from Complex Surveys.” International Statistical Review 51 (3): 279–92. https://doi.org/10.2307/1402588. Binder, David A., and Milojica S. Kovacevic. 1995. “Estimating Some Measures of Income Inequality from Survey Data: An Application of the Estimating Equations Approach.” Survey Methodology 21 (2): 137–45. Dean, Natalie, and Marcello Pagano. 2015. “Evaluating Confidence Interval Methods for Binomial Proportions in Clustered Surveys.” Journal of Survey Statistics and Methodology 3 (4): 484–503. https://doi.org/10.1093/jssam/smv024. Fay, Robert E. 1979. “On Adjusting the Pearson Chi-Square Statistic for Cluster Sampling.” In Proceedings of the Social Statistics Section, American Statistical Association, 402–5. Washington, DC. Fellegi, Ivan P. 1980. “Approximate Tests of Independence and Goodness of Fit Based on Stratified Multistage Samples.” Journal of the American Statistical Association 75: 261–68. Fuller, Wayne A. 1975. “Regression Analysis for Sample Survey.” Sankyha, Series C 37: 117–32. ———. 2002. “Regression Estimation for Survey Samples (with Discussion).” Survey Methodology 28 (1): 5–23. Gutiérrez, H. A. 2016. Estrategias de Muestreo: Diseño de Encuestas y Estimación de Parámetros. Segunda edición. Ediciones de la U. Heeringa, Steven G., Brady T. West, and Patricia A. Berglund. 2017. Applied Survey Data Analysis. Chapman and Hall CRC Statistics in the Social and Behavioral Sciences Series. CRC Press. Kish, Leslie, and Martin R Frankel. 1974. “Inference from Complex Samples.” Journal of the Royal Statistical Society, Series B 36: 1–37. Kovar, J. G., J. N. K. Rao, and C. F. J. Wu. 1988. “Bootstrap and Other Methods to Measure Errors in Survey Estimates.” Canadian Journal of Statistics 16 (Suppl.): 25–45. Langel, Matti, and Yves Tillé. 2013. “Variance Estimation of the Gini Index: Revisiting a Result Several Times Published: Variance Estimation of the Gini Index.” Journal of the Royal Statistical Society: Series A (Statistics in Society) 176 (2): 521–40. https://doi.org/10.1111/j.1467-985X.2012.01048.x. Osier, Guillaume. 2009. “Variance Estimation for Complex Indicators of Poverty and Inequality.” Journal of the European Survey Research Association 3 (3): 167–95. http://ojs.ub.uni-konstanz.de/srm/article/view/369. Pfeffermann, Danny. 2011. “Modelling of Complex Survey Data: Why Model? Why Is It a Problem? How Can We Approach It?” Survey Methodology 37 (2): 115–36. Rao, J. N. K., and A. J. Scott. 1984a. “On Chi-Squared Test for Multiway Contingency Tables with Cell Proportions Estimated from Survey Data.” The Annals of Statistics 12: 46–60. ———. 1984b. “On Chi-Squared Tests for Multiway Contingency Tables with Cell Proportions Estimated from Survey Data.” The Annals of Statistics 12 (1): 46–60. Rust, Keith F., Valerie Hsu, and Westat. 2007. “Confidence Intervals for Statistics for Categorical Variables from Complex Samples.” In. https://api.semanticscholar.org/CorpusID:195852485. Shah, B. V., M. M. Holt, and R. F. Folsom. 1977. “Inference about Regression Models from Sample Survey Data.” Bulletin of the International Statistical Institute 41 (3): 43–57. Skinner, Chris J, Daniell Holt, and Tom M F Smith. 1989. Analysis of Complex Surveys. New York: John Wiley &amp; Sons. Thomas, D. R., and J. N. K. Rao. 1987. “Small-Sample Comparisons of Level and Power for Simple Goodness-of-Fit Statistics Under Cluster Sampling.” Journal of the American Statistical Association 82: 630–36. Wolter, Kirk M. 2007. Introduction to Variance Estimation. 2nd ed. Statistics for Social and Behavioral Sciences. Springer. "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
