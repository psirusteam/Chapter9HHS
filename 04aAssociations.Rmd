# Associations Between Variables

Household surveys often collect data on categorical variables, such as employment status, educational attainment, or access to services. Understanding whether two categorical variables are related, or *associated*, is an important aspect of survey analysis. For example, are employment status and access to the internet connected in a meaningful way? This section introduces methods to describe and infer associations between pairs of categorical variables.

*Understanding Categorical Variables*

Categorical variables are those that divide the population into distinct groups or categories. For example:

- **Employment status** might have categories like "employed," "unemployed," and "not in the labor force."
- **Educational attainment** might include categories such as "primary," "secondary," and "tertiary."

When analyzing associations between two categorical variables, we are interested in whether the distribution of one variable depends on the categories of the other.

*Measuring Associations*

To assess the relationship between two categorical variables, analysts examine how often different combinations of categories occur. For example, they might count how many individuals fall into each pairing of employment status and educational attainment. These counts are then used to calculate proportions, which describe the relative frequency of each pairing within the population.

In practice, this analysis often starts with a **contingency table**, a grid that shows the counts or proportions of units in each combination of categories for the two variables. For example, one axis of the table might list employment statuses, while the other lists levels of educational attainment.

*Hypothesis Testing for Independence*

A key question in association analysis is whether the two variables are **independent** (i.e., whether the distribution of one variable is unaffected by the categories of the other). Hypothesis tests are used to evaluate this. The null hypothesis assumes independence between the variables, while the alternative hypothesis suggests some level of association.

To perform these tests, analysts rely on models that assume the data comes from a larger, hypothetical population (a *superpopulation*). The observed data from the survey is treated as a sample from this superpopulation, and the analysis aims to draw conclusions about the larger population.

*Estimating Population Proportions*

In a perfect scenario, where data is collected from every unit in the population (a census), analysts can directly calculate the proportion of units in each category pairing. However, in most cases, only a sample is available. Weighted estimators, as discussed in previous sections, are used to adjust the sample data so it represents the population accurately. These weighted proportions serve as the basis for calculating associations and conducting hypothesis tests.

*Practical Applications*

Analyzing associations between categorical variables is useful in many contexts, such as:

- **Policy Development**: Understanding the relationship between education and employment helps design effective workforce policies.
- **Program Evaluation**: Assessing whether access to healthcare varies by income level can inform targeted interventions.
- **Social Research**: Studying connections between demographic factors and voting behavior provides insights into societal trends.

*Summary*

Exploring associations between categorical variables is a critical step in household survey analysis. By examining how categories interact and testing for independence, analysts can uncover meaningful relationships that inform policies and programs. Using weighted estimators ensures that the results reflect the population accurately, even when only sample data is available.


## Cross-tabulations and Contingency Tables

### Introduction

Cross-tabulations, also known as contingency tables, are a fundamental tool in survey analysis. They organize data into a table format, showing the frequency distribution of two or more categorical variables. By summarizing relationships between these variables, cross-tabulations help researchers identify patterns and associations that might otherwise go unnoticed.

This type of analysis is widely used in research and policy decision-making, as it provides a straightforward way to explore how different categories interact. For example, a contingency table might examine how employment status varies by educational attainment, or how access to the internet differs between urban and rural households.

### Understanding Contingency Tables

A contingency table is a grid with rows and columns that represent the categories of two variables. Each cell in the table contains the frequency or proportion of observations that fall into the corresponding combination of categories. For instance:

- The rows might represent categories of one variable, such as "employment status" (employed, unemployed, not in the labor force).
- The columns might represent categories of another variable, such as "education level" (primary, secondary, tertiary).

The table can also include **marginal totals**, which summarize the data for each row or column, and a **grand total**, representing the overall population.

### Weighted Frequencies

In household surveys, frequencies in contingency tables are calculated using survey weights. These weights ensure that the estimates accurately reflect the entire population, accounting for the sampling design. For each cell, the weighted frequency represents the estimated number of individuals in the population with the corresponding combination of categories.

Weighted frequencies can also be converted into **proportions**, which indicate the relative size of each group compared to the total population. Proportions are particularly useful when comparing groups of different sizes or when focusing on the relative distribution of categories.

### Applications of Cross-tabulations

Cross-tabulations are versatile and widely used in various contexts, including:

- **Policy Analysis**: Examining how access to healthcare varies by income level can inform targeted interventions.
- **Program Evaluation**: Understanding the distribution of educational attainment across regions helps evaluate the impact of education policies.
- **Market Research**: Identifying patterns in consumer behavior based on demographic variables supports targeted marketing strategies.

### Visualizing Cross-tabulations

While tables are a clear way to present data, visualizations such as stacked bar charts or heatmaps can enhance understanding by highlighting patterns and differences between categories. These visuals complement contingency tables, making it easier to communicate findings to a broad audience.

### Summary

Cross-tabulations and contingency tables are essential tools for analyzing relationships between categorical variables. By organizing data into clear and interpretable formats, they help researchers and policymakers uncover meaningful patterns and associations. Weighted frequencies and proportions ensure that the analysis reflects the population accurately, making these tools invaluable in household survey analysis.


## Testing for Independence

### Introduction

In household surveys, it is often important to determine whether two categorical variables are associated or independent. For example, is there a relationship between educational attainment and employment status? To answer such questions, independence tests are used. These tests compare the observed data with what would be expected if the two variables were completely unrelated.

### Hypothesis Testing

The starting point for testing independence is the **null hypothesis**, which assumes that the two variables are independent. This means the likelihood of being in any combination of categories is simply the product of their marginal probabilities.

To test this hypothesis, observed frequencies (or proportions) in a contingency table are compared with the expected frequencies under the null hypothesis. If the observed and expected values differ significantly, the null hypothesis of independence is rejected, suggesting an association between the variables.

### Adjusted Test Statistics

Testing for independence in survey data requires adjustments to account for the sampling design, which often includes stratification, clustering, and unequal probabilities of selection. The **Rao-Scott adjustment** modifies traditional chi-square tests to incorporate these design effects.

1. **Pearson Rao-Scott Test**:
   - This test compares observed and expected proportions.
   - The test statistic is adjusted for the survey design using a measure called the **generalized design effect (GDEFF)**, which accounts for the complexity of the sampling design.
   - The adjusted statistic follows a chi-square distribution under the null hypothesis.

2. **Likelihood Ratio Test**:
   - This test uses the ratio of observed to expected proportions to assess independence.
   - Similar to the Pearson test, the likelihood ratio test statistic is adjusted for the survey design and follows a chi-square distribution under the null hypothesis.

### Adjustments for Small Samples

When the sample size or degrees of freedom is small, adjustments to the test statistics can improve accuracy. These adjustments use an **F-distribution** instead of the chi-square distribution, making the tests more robust for smaller datasets. Adjusted test statistics include:

- **F-adjusted Pearson test**: Based on the Rao-Scott Pearson chi-square statistic.
- **F-adjusted Likelihood Ratio test**: Based on the Rao-Scott adjusted likelihood ratio statistic.

### Practical Applications

Independence tests are commonly used in survey analysis to answer questions like:

- Is access to healthcare independent of income level?
- Are voting preferences associated with age groups?
- Does educational attainment influence internet usage?

These tests provide valuable insights into relationships between variables, helping researchers and policymakers make informed decisions.

### Software Implementation

Modern statistical software, such as R, Stata, and SAS, includes functions to perform these adjusted independence tests. For example:

- In R, the `survey` package allows users to calculate Rao-Scott adjusted chi-square and likelihood ratio tests.
- Stata and SAS provide similar tools for working with complex survey data.

### Summary

Testing for independence in categorical variables is a vital component of survey data analysis. Adjustments like the Rao-Scott modification ensure that these tests are accurate and account for the complexities of survey designs. By comparing observed and expected proportions, these tests help identify meaningful associations that can inform research and policy.


## Tests for Group Comparisons

### Introduction

Comparing group means is a common goal in household survey analysis. For example, researchers might ask: "Is there a significant difference in average income between male- and female-headed households?" To answer such questions, statistical tests like the t-test are used, adapted to account for the complexities of survey data, such as stratification, clustering, and unequal selection probabilities.

This section explains the methods for testing differences in means, adjusted for survey design, with examples to illustrate their application.


### Hypothesis Testing for Differences in Means

#### **Setting Up Hypotheses**

A hypothesis test evaluates evidence from the sample data to decide whether to reject a null hypothesis (\(H_0\)) in favor of an alternative hypothesis (\(H_1\)). For group comparisons, the hypotheses are usually structured as:

- **Null hypothesis (\(H_0\))**: The population means are equal (\(\mu_1 - \mu_2 = 0\)).
- **Alternative hypothesis (\(H_1\))**: The population means differ (\(\mu_1 - \mu_2 \neq 0\)).

Other alternatives might test whether one mean is specifically larger or smaller than the other:

1. \(H_1: \mu_1 - \mu_2 > 0\) (mean of Group 1 is larger).
2. \(H_1: \mu_1 - \mu_2 < 0\) (mean of Group 1 is smaller).


#### **Estimating the Difference in Means**

For two groups, the difference in population means is estimated from the sample as:

\[
\widehat{\mu}_1 - \widehat{\mu}_2
\]

where \(\widehat{\mu}_j\) is the weighted sample mean for Group \(j\) (e.g., mean income for male- and female-headed households). The weights adjust for the survey design, ensuring the estimate represents the population.

**Example**: Suppose the survey data show:
- Average income of male-headed households (\(\widehat{\mu}_1\)): \$50,000
- Average income of female-headed households (\(\widehat{\mu}_2\)): \$40,000

The estimated difference is:

\[
\widehat{\mu}_1 - \widehat{\mu}_2 = 50,000 - 40,000 = 10,000
\]


#### **Variance and Standard Error**

To assess the reliability of the estimate, we calculate its variance:

\[
Var \left( \widehat{\mu}_1 - \widehat{\mu}_2 \right) = Var(\widehat{\mu}_1) + Var(\widehat{\mu}_2) - 2 \times Cov(\widehat{\mu}_1, \widehat{\mu}_2)
\]

The standard error (SE) is the square root of the variance. It reflects the uncertainty in the estimate due to sampling variability.

**Example**: If:
- \(Var(\widehat{\mu}_1) = 4,000^2\),
- \(Var(\widehat{\mu}_2) = 3,500^2\), and
- \(Cov(\widehat{\mu}_1, \widehat{\mu}_2) = 500^2\),

then:

\[
Var = 4,000^2 + 3,500^2 - 2 \times 500^2 = 32,250,000
\]

The standard error is:

\[
SE = \sqrt{32,250,000} \approx 5,678
\]


#### **Test Statistic**

The test statistic is calculated as the ratio of the estimated difference to its standard error:

\[
t = \frac{\widehat{\mu}_1 - \widehat{\mu}_2}{SE}
\]

The \(t\)-statistic follows a \(t\)-distribution with degrees of freedom (\(df\)) based on the survey design (e.g., the number of primary sampling units and strata).

**Example**: Using the previous estimate:

\[
t = \frac{10,000}{5,678} \approx 1.76
\]


### Confidence Intervals for the Difference in Means

A confidence interval (CI) provides a range within which the true difference likely lies. It is calculated as:

\[
\left( \widehat{\mu}_1 - \widehat{\mu}_2 \right) \pm t_{[df]} \times SE
\]

**Example**: With \(t_{[df]} = 2.02\) for 95% confidence and \(SE = 5,678\):

\[
CI = 10,000 \pm 2.02 \times 5,678
\]

\[
CI = \left( 10,000 - 11,462, \, 10,000 + 11,462 \right)
\]

\[
CI = (-1,462, 21,462)
\]

Since the CI includes zero, the test suggests the difference is not statistically significant.


### Practical Applications


#### 1. **Income Comparisons**  
Income comparisons are often used to understand socioeconomic inequalities or evaluate the impact of policies. Examples include:
   - Comparing the average income of households in urban versus rural areas to assess regional disparities.
   - Analyzing wage gaps by gender, age group, or education level to identify inequities in the labor market.
   - Evaluating the effect of minimum wage laws by comparing average incomes before and after policy implementation.

#### 2. **Health Studies**  
Differences in healthcare outcomes are critical for identifying gaps in access or the impact of health interventions. Examples include:
   - Comparing average healthcare expenditure between insured and uninsured households to assess the financial burden of medical care.
   - Analyzing differences in average hospital visits for households in regions with varying levels of healthcare access.
   - Evaluating the impact of a vaccination program by comparing average rates of disease incidence in vaccinated versus unvaccinated groups.

#### 3. **Education Studies**  
Educational outcomes can be compared across groups to assess inequalities or program impacts. Examples include:
   - Comparing average test scores between students in private and public schools to examine differences in educational quality.
   - Analyzing the impact of a scholarship program by comparing average graduation rates of recipients versus non-recipients.
   - Investigating gender differences in average years of schooling to identify potential barriers to education.

#### 4. **Program Evaluation**  
Social programs and interventions are often evaluated by comparing outcomes between participants and non-participants. Examples include:
   - Assessing the impact of job training programs by comparing average employment rates of trainees versus non-trainees.
   - Measuring the effectiveness of food assistance programs by comparing average caloric intake for beneficiaries and non-beneficiaries.
   - Evaluating housing subsidies by comparing average rent burdens between recipients and non-recipients.

#### 5. **Demographic Studies**  
Demographic variables like age, marital status, or household size can influence various outcomes. Examples include:
   - Comparing average household size between regions to study cultural or economic differences.
   - Analyzing differences in average childbearing age across educational levels to understand fertility trends.
   - Comparing average life expectancy for males versus females to identify health disparities.

#### 6. **Consumer Behavior**  
Household surveys often collect data on expenditure and consumption patterns, which can be compared across groups. Examples include:
   - Comparing average spending on groceries between households with and without children to understand cost differences.
   - Analyzing differences in average utility expenditures between urban and rural households to identify infrastructure disparities.
   - Investigating spending on luxury goods by income bracket to study consumer preferences.

#### 7. **Environmental Studies**  
Household surveys can also assess environmental behaviors and impacts. Examples include:
   - Comparing average energy consumption between households using renewable versus non-renewable energy sources.
   - Analyzing differences in average water usage between urban and rural areas to support resource management policies.
   - Evaluating the impact of recycling campaigns by comparing average waste output for campaign participants and non-participants.

### Summary of Applications

These examples demonstrate the versatility of group comparison tests across various domains. Whether in income analysis, health research, program evaluation, or environmental studies, these methods provide valuable insights into group-level differences, supporting data-driven policy and decision-making. Testing for differences in group means is essential for analyzing household survey data. By adjusting for the survey design, these tests provide accurate insights into population-level differences. Whether comparing incomes, health outcomes, or program impacts, hypothesis testing enables researchers to make data-driven decisions with confidence.


## NSO â€“ Practical Example

In this section, we present how a National Statistical Office (NSO) manages statistical comparisons among groups and shares the results through clear and accessible tables. This practical example provides insights into best practices for producing and disseminating group comparison results.

### Statistical Comparisons Among Groups

National Statistical Offices often conduct statistical comparisons to analyze differences between population groups based on survey data. For example:

- **Labor Market Analysis**: Comparing employment rates between urban and rural areas or different age groups.
- **Education Analysis**: Assessing differences in average years of schooling between genders or regions.
- **Income Studies**: Investigating wage disparities between various occupational categories.

The NSO follows a structured approach to ensure the results are accurate and interpretable:

1. **Adjusting for Survey Design**: 
   - The NSO applies weights to account for the complex survey design, including stratification, clustering, and unequal probabilities of selection.
   - Adjusted variances and confidence intervals are calculated to reflect the design effects.

2. **Hypothesis Testing**:
   - Tests are performed to determine whether differences between group means are statistically significant.
   - The NSO uses t-tests or similar statistical methods tailored to survey data to compare means or proportions.

3. **Sensitivity Checks**:
   - The NSO conducts robustness checks to ensure that results hold across different subsamples or under alternative assumptions.

### Presentation of Results in Tables

The NSO places a strong emphasis on presenting results in a clear and understandable format, ensuring that data users, including policymakers, researchers, and the public, can easily interpret the findings. Common practices include:

#### 1. **Simple and Intuitive Layouts**
Tables are organized with rows representing groups (e.g., male- and female-headed households) and columns showing key metrics (e.g., means, standard errors, and confidence intervals). An example table might look like this:

| Group                 | Mean Income ($) | Standard Error ($) | 95% Confidence Interval ($) |
|-----------------------|-----------------|---------------------|-----------------------------|
| Male-headed households | 50,000          | 1,200               | [47,600, 52,400]           |
| Female-headed households | 40,000          | 1,500               | [37,000, 43,000]           |

#### 2. **Highlighting Key Findings**
Statistically significant differences are highlighted using:
   - Bold font for significant estimates.
   - Asterisks to indicate levels of significance (e.g., ***p < 0.01**).

For example:

| Group                 | Mean Income ($) | Difference ($) | Significance |
|-----------------------|-----------------|----------------|--------------|
| Male-headed households | 50,000          |                |              |
| Female-headed households | 40,000          | -10,000        | ***          |

#### 3. **Descriptive Notes**
Each table includes notes that explain:
   - The survey design and adjustments made.
   - The methods used to calculate confidence intervals and test significance.
   - Any limitations or caveats in the analysis.

#### 4. **Visual Aids**
Whenever possible, the NSO complements tables with graphs or charts to visually illustrate group differences. For instance:
   - Bar charts for mean comparisons.
   - Error bars to depict confidence intervals.

### Practical Example

In a recent labor market study, the NSO compared employment rates between urban and rural areas. The results were presented as follows:

| Area    | Employment Rate (%) | Standard Error (%) | 95% Confidence Interval (%) |
|---------|---------------------|---------------------|-----------------------------|
| Urban   | 75.0                | 1.5                 | [72.0, 78.0]               |
| Rural   | 65.0                | 2.0                 | [61.0, 69.0]               |

The NSO concluded that employment rates were significantly higher in urban areas. This finding was emphasized in a press release, along with visualizations and policy implications.

### Summary

By following rigorous methods and presenting results in accessible formats, NSOs ensure that statistical comparisons among groups are both accurate and actionable. Clear tables, descriptive notes, and visual aids make the findings easy to interpret, enabling policymakers and other stakeholders to make data-driven decisions.


